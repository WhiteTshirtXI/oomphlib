//LIC// ====================================================================
//LIC// This file forms part of oomph-lib, the object-oriented, 
//LIC// multi-physics finite-element library, available 
//LIC// at http://www.oomph-lib.org.
//LIC// 
//LIC//           Version 0.85. June 9, 2008.
//LIC// 
//LIC// Copyright (C) 2006-2008 Matthias Heil and Andrew Hazel
//LIC// 
//LIC// This library is free software; you can redistribute it and/or
//LIC// modify it under the terms of the GNU Lesser General Public
//LIC// License as published by the Free Software Foundation; either
//LIC// version 2.1 of the License, or (at your option) any later version.
//LIC// 
//LIC// This library is distributed in the hope that it will be useful,
//LIC// but WITHOUT ANY WARRANTY; without even the implied warranty of
//LIC// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
//LIC// Lesser General Public License for more details.
//LIC// 
//LIC// You should have received a copy of the GNU Lesser General Public
//LIC// License along with this library; if not, write to the Free Software
//LIC// Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
//LIC// 02110-1301  USA.
//LIC// 
//LIC// The authors may be contacted at oomph-lib@maths.man.ac.uk.
//LIC// 
//LIC//====================================================================
#ifndef OOMPH_DISTRIBUTED_VECTOR_CLASS_HEADER
#define OOMPH_DISTRIBUTED_VECTOR_CLASS_HEADER

// Config header generated by autoconfig
#ifdef HAVE_CONFIG_H
  #include <oomph-lib-config.h>
#endif

// MPI ONLY
#ifdef OOMPH_HAS_MPI

// General mpi header
//#include "mpi.h"

// oomph headers
#include "../generic/Vector.h"
#include "../generic/matrices.h"
#include "../generic/distribution_info.h"

namespace oomph{

//=============================================================================
/// \short A Distributed Vector. Just contains an oomph stl vector, a 
/// DistributionInfo object and the functionality to alter and access them
/// while ensuring they remain synchronised (e.g. the size of the vector being
/// equal to nrow_local of the DistributionInfo)
//=============================================================================
template<typename T> class DistributedVector
{                                                        
 
 public :                     
  
  /// \short Constructor for a distribution vector that has not been setup. 
  /// The member fn distribute(...) will need to be called to setup this 
  /// distributed vector
  DistributedVector(){}
 
 /// \short Constructor. Assembles a distributed vector with distribution 
 /// dist, if v is specified each row is set to v. NOTE: the distribution
 /// must be setup
 DistributedVector(const DistributionInfo& dist, const T& v = T())
  {
   distribute(dist,v);
  }
 
 /// \short Constructor. Assembes a distributed vector with distribution 
 /// dist, from the non-distributed vector v. NOTE: the distribution must
 /// be setup
 DistributedVector(const DistributionInfo& dist, const Vector<T>& v)
  {
   distribute(dist,v);
  }
   
 /// Destructor - does nothing
 ~DistributedVector(){}                 
 
 /// Copy constructor
 DistributedVector(const DistributedVector& distributed_vector)
  : Vector_distribution(distributed_vector.distribution()),
  Local_vector(distributed_vector.vector())
  {}
 
 /// assignment operator
 void operator=(const DistributedVector& distributed_vector)
  {
   Local_vector = distributed_vector.vector();
   Vector_distribution = distributed_vector.distribution();
  }
 
 /// \short Assembles a distributed vector with distribution  dist, if v is 
 /// specified each row is set to v. NOTE: the distribution must be setup
 void distribute(const DistributionInfo& dist, const T& v = T())
  {
#ifdef PARANOID
   // paranoid check distribution is setup
   if (!dist.setup())
    {
     throw OomphLibError("DistributionInfo dist has not been set.",
                         "DistributedVector::distribute()",
                         OOMPH_EXCEPTION_LOCATION);
    }   
#endif    
   
   // Set my dist to the incoming distribution
   Vector_distribution = dist;
   
   // resize the vector and set every row to v
   Local_vector.resize(dist.nrow_local(),v);
  }
 
 /// \short  Assembes a distributed vector with distribution  dist, from the 
 /// non-distributed vector v. NOTE: the disitrbution must be setup
 void distribute(const DistributionInfo& dist, const Vector<T>& v)
  {
#ifdef PARANOID
   // paranoid check distribution is setup
   if (!dist.setup())
    {
     throw OomphLibError("DistributionInfo dist has not been set.",
                         "DistributedVector::distribute(...)",
                         OOMPH_EXCEPTION_LOCATION);
    }   
   // paranoid check that the non-dist vector is the correct size
   if (dist.nrow_global() != v.size())
    {
     std::ostringstream error_message;    
     error_message << "The size of the non-distributed vector v ("
                   << v.size() << ") is not equal to the number of global "
                   << "global rows in the DistributionInfo dist ("
                   << dist.nrow_global() << ").\n";
     throw OomphLibError(error_message.str(),
                         "DistributedVector::distribute(...)",
                         OOMPH_EXCEPTION_LOCATION);
    }   
#endif    
   
   // Set my dist to the incoming distribution
   Vector_distribution = dist;
   
   // copy the required rows from the non-dist vector v
   unsigned nrow = dist.nrow_local();
   unsigned first_row = dist.first_row();
   Local_vector.resize(nrow);
   Local_vector.assign(v.begin()+first_row,v.begin()+first_row+nrow);
  }
 
 /// \short removes all elements from the vector and clears the distribution
 void clear() 
  {
   Local_vector.clear();
   Vector_distribution.clear();
  }
 
 /// \short The contents of the vector are redistributed to match the new
 /// distribution. The number of global rows must not change. NOTE: both
 /// the incoming DistributionInfo dist and this DistributedVector's 
 /// Distribution Dist must be setup.
 void redistribute(DistributionInfo& new_dist);
 
 /// \short returns the full non-distributed vector on every processor
 /// NOTE: when/if mpi_src and src are merged this will probably be a
 /// constructor/function of the standard non-distributed vector
 void global_vector(Vector<T>& v);
 
 /// access function to the distribution (object: DistributionInfo)
 DistributionInfo& distribution() { return Vector_distribution; }
 
 /// access function to the vector
 Vector<T>& vector() { return Local_vector; }
 
 /// access function to the distribution (const version)
 DistributionInfo distribution() const { return Vector_distribution; }
 
 /// access function to the vector (const version)
 Vector<T> vector() const { return Local_vector; }
 
 /// access function to first row 
 unsigned long first_row(const unsigned& p = MPI_Helpers::My_rank) const
  { return Vector_distribution.first_row(p); }
 
 /// access function to nrow_local
 unsigned long nrow_local(const unsigned& p = MPI_Helpers::My_rank) const
  { return Vector_distribution.nrow_local(p); }
 
 /// access function to nrow_global
 unsigned long nrow_global() const 
  { return Vector_distribution.nrow_global(); }
 
 /// access function to setup
 bool setup() const { return Vector_distribution.setup(); }
 
 /// [] operator (const version) access to the local vector
 const T& operator[]( typename Vector<T>::size_type i ) const
  { return Local_vector[i]; }
 
 /// [] operator access to the local vector
 T& operator[](typename Vector<T>::size_type i )
  { return Local_vector[i]; }
 
 private :
  
  /// the distribution   
  DistributionInfo Vector_distribution;  
 
 /// the local vector
 Vector<T> Local_vector;                                      
 
}; //end of DistributedVector                 

 //============================================================================
 /// \short The contents of the vector are redistributed to match the new
 /// distribution. The number of global rows must not change. NOTE: both
 /// the incoming DistributionInfo dist and this DistributedVector's 
 /// Distribution Dist must be setup. \n
 /// WARNING: currently this method will only if the communicators in the 
 /// old distribution and the new distribution are the same 
 //============================================================================
template<typename T> 
void DistributedVector<T>::redistribute(DistributionInfo& new_dist)
{
#ifdef PARANOID
 // paranoid check that current distribution is already setup
 if (!Vector_distribution.setup())
  {
   throw OomphLibError("This DistributedVector has not been set.",
                       "DistributedVector::redistribute(...)",
                       OOMPH_EXCEPTION_LOCATION);
  }
 // paranoid check distribution is setup
 if (!new_dist.setup())
  {
   throw OomphLibError("DistributionInfo dist has not been set.",
                       "DistributedVector::redistribute(...)",
                       OOMPH_EXCEPTION_LOCATION);
  } 
 // paranoid check that the nrow_globals for both distributions is the 
 // same
 if (new_dist.nrow_global() != Vector_distribution.nrow_global())
  {
   std::ostringstream error_message;    
   error_message << "The number of global rows in the new distribution ("
                 << new_dist.nrow_global() << ") is not equal to the number"
                 << " of global rows in the current distribution ("
                 << Vector_distribution.nrow_global() << ").\n"; 
   throw OomphLibError(error_message.str(),
                       "DistributedVector::redistribute(...)",
                       OOMPH_EXCEPTION_LOCATION);
  }
#endif  
 
 // check the distributions are not the same
 if (Vector_distribution != new_dist)
  {

   // compare the communicators
   int comm_flag;
   
   MPI_Comm_compare(Vector_distribution.communicator(),
                    new_dist.communicator(),&comm_flag);
   if (comm_flag != MPI_IDENT)
    {
     std::ostringstream error_message;
     error_message << "The communicator in the current distribution and "
                   << "the communicator in the new distribution are not "
                   << " the same.\n In this implementation of redistribute()"
                   << " they must be.\n"; 
     throw OomphLibError(error_message.str(),
                         "DistributedVector::distribute(...)",
                         OOMPH_EXCEPTION_LOCATION);
    }

   // get the rank and the number of processors
   int my_rank;
   MPI_Comm_rank(new_dist.communicator(),&my_rank);
   int n_proc;
   MPI_Comm_size(new_dist.communicator(),&n_proc);
   
   // get the new distribution of every processor
   Vector<long unsigned> new_first_row(n_proc);
   Vector<long unsigned> new_nrow_local(n_proc);
   MPI_Comm new_comm;
   new_dist.full_distribution(new_comm,new_first_row,new_nrow_local);
   
   // vector of vectors to store the local rows in terms of the processor
   // they will be on, come the redistribution
   // NOTE the index is the local index in the new distribution
   Vector<Vector<T> > row_value_for_processor(n_proc);
   Vector<Vector<int> > row_index_for_processor(n_proc);
   
   // loop over my rows and determine where they should be
   for (unsigned i = 0; i < Vector_distribution.nrow_local(); i++)
    {
     // determine which processor this row will be on when the
     // re-distribution is complete
     unsigned p = 0;
     while (!(Vector_distribution.first_row() + i >= new_first_row[p] && 
              Vector_distribution.first_row() + i <  (new_first_row[p] + 
                                                      new_nrow_local[p])))
      {p++;}
     
     // add to set of rows for processor p from this processor
     row_value_for_processor[p].push_back(Local_vector[i]);
     row_index_for_processor[p].push_back(Vector_distribution.first_row() 
                                          + i - new_first_row[p]);
    }
   
   // vector of vectors to store the local rows of the redistributed 
   // matrix in terms of the processor that it came from
   Vector<Vector<T> > row_value_from_processor(n_proc);
   Vector<Vector<int> > row_index_from_processor(n_proc);
   
   // send and receive circularly
   for (int p = 1; p < n_proc; p++)
    {
     // next processor to send to
     unsigned dest_p = (my_rank + p)%n_proc;
     
     // next processor to receive from
     unsigned source_p = (n_proc + 
                          my_rank - p)%n_proc;
     
     // size of vector to be sent
     int n_send = row_index_for_processor[dest_p].size();
     
     // size of vector to recv
     int n_recv;

     // find size of vector to be recv
     MPI_Status status;
     MPI_Sendrecv(&n_send,1,MPI_INT,dest_p,0,&n_recv,1,MPI_INT,source_p,0,
                  new_dist.communicator(),&status);

     // send and receive the index
     MPI_Sendrecv(&row_index_for_processor[dest_p],
                  n_send,MPI_INT,dest_p,0,
                  &row_index_from_processor[source_p],
                  n_send,MPI_INT,source_p,0,new_dist.communicator(),&status);
     row_index_for_processor[dest_p].clear();
     
     // send and receive the value
     MPI_Sendrecv(&row_value_for_processor[dest_p],
                  n_send,MPI_DOUBLE,dest_p,1,
                  &row_value_from_processor[source_p],
                  n_recv,MPI_DOUBLE,source_p,1,new_dist.communicator(),
                  &status);
     row_value_for_processor[dest_p].clear();
    }
   
   // copy my rows from my "for" vector to my "from" vector
   row_index_from_processor[my_rank] = 
    row_index_for_processor[my_rank];
   row_index_for_processor[my_rank].clear();
   row_value_from_processor[my_rank] =    
    row_value_for_processor[my_rank];
   row_value_for_processor[my_rank].clear();
   
   // assemble the new distribution on this processor
   Local_vector.resize(Vector_distribution.nrow_local());
   for (int p = 0; p < n_proc; p++)
    {
     unsigned nrow_from_p = row_index_from_processor[p].size();
     for (unsigned i = 0; i < nrow_from_p; i++)
      {
       Local_vector[row_index_from_processor[p][i]] = 
        row_value_from_processor[p][i];
      }
     row_index_from_processor[p].clear();
     row_value_from_processor[p].clear();
    }
   
   // update the distribution
   Vector_distribution = new_dist;
  }
}

//============================================================================
/// \short returns the full non-distributed vector on every processor
//============================================================================
template<typename T> 
void DistributedVector<T>::global_vector(Vector<T>& v)
{

 // get the rank and the number of processors
 int my_rank;
 MPI_Comm_rank(Vector_distribution.communicator(),&my_rank);
 int n_proc;
 MPI_Comm_size(Vector_distribution.communicator(),&n_proc);
 
#ifdef PARANOID
 if (!Vector_distribution.setup())
  { 
   throw OomphLibError("DistributionInfo has not been set.",
                       "DistributedVector::global_vector()",               
                       OOMPH_EXCEPTION_LOCATION);
  }                                                           
#endif  
 
 // resize the global vector
 v.resize(Vector_distribution.nrow_global());
 
 // create a int vector of first rows
 int* dist_first_row = new int[n_proc];
 int* dist_nrow_local =  new int[n_proc];
 for (int p = 0; p < n_proc; p++)
  {
   dist_first_row[p] = this->first_row(p);
   dist_nrow_local[p] = this->nrow_local(p);
  }
 
 // gather the local vectors from all processors on all processors
 int my_nrow_local(this->nrow_local());
 int mpi_error_flag = 
  MPI_Allgatherv(&Local_vector[0],my_nrow_local,MPI_DOUBLE,
                 &v[0],dist_nrow_local,dist_first_row,MPI_DOUBLE,
                 Vector_distribution.communicator());
 if (mpi_error_flag != 0)
  {
   std::ostringstream error_message;
   error_message << "MPI_Allgatherv Error : mpi_error_flag = " 
                 << mpi_error_flag;
   throw OomphLibError(error_message.str(),
                       "DistributedVector::global_vector(...)",
                       OOMPH_EXCEPTION_LOCATION);
  }
}
} // end of oomph namespace

#endif // OOMPH_HAS_MPI endif
#endif
