\mainpage A discussion on oomph-lib's Block Preconditioning Framework


In this document we discuss \c oomph-libs block preconditioning
framework. We describe the functionality of the framework by starting with 
discussing the implementation of a simple block diagonal
preconditioner, ...



The aim of the block preconditioning framework is to provide a simple 
environment to facilitate the implementation of distributed block 
preconditioners which in particular allows existing (block) preconditioners to 
be reused to create in hierarchical fashion new block preconditioners for 
multi-physics problems. In some examples we will reuse existing general purpose
block preconditioners for the subsidiary problems.


\section theory Theoretical Background

In \c oomph-lib, all problems are solved by Newton's method,
which requires the repeated solution of linear systems of the form

\f[
J\;{\bf \delta x}=-{\bf r}
\f]

for the Newton correction \f$\bf \delta x\f$ where \f$J\f$ is the
Jacobian matrix and \f$\bf r\f$ is the vector of residuals. (Left) 
preconditioning represents a transformation of the original linear system to

\f[
P^{-1}J\;{\bf \delta x}=-P^{-1}{\bf r}
\f]

introduced with the aim of accelerating the convergence of Krylov subspace 
iterative methods such as GMRES or CG. The application of the preconditioner 
requires the solution of

\f[
P{\bf z}={\bf y}
\f]

for \f$\bf z\f$ at each Krylov iteration.

Block preconditioning requires special enumeration schemes for the unknowns 
(equivalent to reordering the linear systems) where all the unknowns 
corresponding to each type of DOF are grouped together and enumerated 
consecutively. This leads to a natural block structure of the linear systems.

For instance, linear elasticity problems (discussed <a href="../../../linear_elasticity/periodic_load/html/index.html">here</A>) involve the solid (the nodal positions in the solid domain) degrees of freedom (DOFs). Consider the two-dimensional case, we begin by reordering the linear system to group together the two types of DOF 

\f[
\left[ 
\begin{array}{cc}
S_{xx}&S_{xy}\\
S_{xy}&S_{yy}
\end{array}
\right]
\left[ 
\begin{array}{c}
\bf \delta x_x\\
\bf \delta x_y\\
\end{array}
\right]
=
-
\left[
\begin{array}{c}
\bf r_x\\
\bf r_y\\
\end{array}
\right],
\f]

The block diagonal preconditiner of the form 
\f[
P_{diag}=
\left[
\begin{array}{cc}
S_{xx}& \\
      &S_{yy}
\end{array}
\right]
\f]
is obtained by omitting the off-diagonal blocks from the Jacobian.

The application of the preconditioner requires the solution of the linear system

\f[
\left[
\begin{array}{cc}
S_{xx}& \\
      &S_{yy}
\end{array}
\right]
\left[
\begin{array}{c}
\bf z_x\\
\bf z_y\\
\end{array}
\right]
=
\left[
\begin{array}{c}
\bf y_x\\
\bf y_y
\end{array}
\right],
\f]

the two sub-blocks are solved directly.

\section generic_implementation Framework Overview

The above example shows that the application of block preconditioners
require several generic steps:

-# The classification of the DOFs.
-# The application of subsidiary preconditioning operators.

The following subsections describe how these tasks are performed
within \c oomph-lib's block preconditioning framework.

\subsection block_preconditionable_elements Block Preconditionable Elements

The classification of DOFs is implemented at an elemental level. The class \c GeneralisedElement
contains two broken virtual methods that must be re-implemented to
label the DOFs with their type. The methods are:

- \c GeneralisedElement::ndof_types() must return the number of DOF types
  associated with an element.
- \c GeneralisedElement::get_dof_numbers_for_unknowns(...) must return a list of pairs
  comprising a map from global equation number to DOF type for all unknowns
  in the element.

These are already implemented for many elements. For instance the two-dimensional FSI channel with leaflet problem has two types of element:

- \c RefineableQTaylorHoodElement<2> are the fluid elements. They have three types of DOF; \f$x\f$-velocity DOFs are labelled \c 0, \f$y\f$-velocity DOFs are labelled \c 1 and
  the pressure DOFs are labelled \c 2.
- \c FSIHermiteBeamElement are the wall elements and have one type of
  DOF (the nodal position) labelled \c 0.

The linear elasticity elements are made block-preconditionable with a wrapper
around the element implemented in the driver code.

\dontinclude two_d_linear_elasticity_with_simple_block_diagonal_preconditioner.cc
\skipline  start_of_mylinearelasticityelement
\until };
Thus, in the \c MyLinearElasticityElement<2> we have two types of DOF; corresponding to the \f$x\f$ and \f$y\f$ directions. They are enumerated \c 0 and \c 2 respectively.

\subsection dof_types_and_block_types DOF Types and Block Types

In the block diagonal preconditioner for the two-dimensional linear elasticity problem, there are two block types. There are also two DOF types. However, in more complicated preconditioners, such as the <a href="../../../preconditioners/lsc_navier_stokes/html/index.html"> Least-Squares Commutator (LSC) Navier-Stokes preconditioner</A>, there are more DOF types than there are block types. The relationship between DOF types, block types, elemental DOF type classification and meshes are:

- \b Elemental \b DOF \b type \b classification: Each element classifies it's own DOF type in the function \c get_dof_numbers_for_unknowns(...). In the case of \c MyLinearElasticityElement<2> elements, the DOF types are classified as \c 0 and \c 1. For \c QTaylorHoodElement<2> elements, the DOF types are classified as \c 0 and \c 1 for the \f$x\f$ and \f$y\f$-velocities, and \c 2 for the pressure \f$p\f$. 

- \b Role \b of \b mehes: Each mesh acts as a container for a set of DOF type classifications for a particular element. If two different elements types are put in to the same mesh, then their \c ndof_types() should return the same number and their DOF type classifications will be treated the same. For example, the \c QTaylorHoodElement<2> classifies the DOF types as follows:
 - \c 0 \f$x\f$-velocity
 - \c 1 \f$y\f$-velocity
 - \c 2 \f$p\f$-pressure
 .
 If we wish to impose parallel outflow along a boundary, we attach \c ImposeParallelOutflowElement<ELEMENT>, see <a href="../../../navier_stokes/vmtk_fluid/html/index.html"> demo problem: Steady finite-Reynolds-number flow through an iliac bifurcation </A>, these \c FaceElements classifies the bulk DOF types as follows:
 - \c 0 \f$x\f$-constrained velocity
 - \c 1 \f$y\f$-constrained velocity
 - \c 2 \f$L\f$-Lagrange multiplier
 .
 Although the \c ndof_types() for these two different elements are the same, there are clearly six distinct DOF types. To ensure that the block preconditioning framework treats these as different DOF types, we must have two meshes for the two different type of elements. If we put the two elements in the same mesh, then the block preconditioning framework will not distinguish between the two \c 0 DOF types, \c 1 DOF types and \c 2 DOF types.
- \b DOF \b types \b in \b the \b block \b preconditioner: The different meshes instructs the block preconditioning framework how to order the DOF types (the \c ndof_types() function provides an offset). For example, consider the above \c vmtk problem, the first mesh (the bulk mesh) says the first three DOF types are \c 0 , \c 1 and \c 2 (we know that this corresponds to the \f$x\f$ and \f$y\f$-velocities and pressure). At this stage the offset is \c 0 and the DOF types in the block preconditioner are \c 0+0 , \c 1+0 and \c 2+0. The second mesh (the surface mesh) also has DOF types \c 0 , \c 1 and \c 2, but because it is a different mesh, the offset is now updated to the sum of the \c ndof_types() of the first element in all previous meshes (hence it is vital that the \c ndof_types() of all the elements in a single mesh is the same, although the elements may be different), in this case it is \c 3. The DOF types in the block preconditioner for the surface mesh DOF types are \c 0+3 , \c 1+3 \c 2+3 (which we know corresponds to the constrained \f$x\f$ and \f$y\f$-velocities and the Lagrange multiplier DOF type). It is important to note that the order of the meshes determines how the DOF types are enumerated in the block preconditioner, the block preconditioner should handle the ordering of the meshes, the user should use functions such as \c set_navier_stokes_mesh(...) in the case of the \c NavierStokesSchurComplementPreconditioner.
Note: Each DOF can be classified more than once. The classification should be the last mesh visited by the block preconditioning framework. This should not be an issue if you do not have discontinuous boundary conditions.
- \b Block \b types: The block types are the sub-blocks of matrices the block preconditioner works with. They may contain more than one DOF type or be as fine grain as the number of DOF types. Note: There can not be more block types than there are DOF types in the block preconditioner. For example, in case of the the LSC preconditioner (in 2D) we have three DOF types (\f$x\f$ and \f$y\f$-velocities and pressure), but it works with just two block types (velocity block and pressure block). The setup of the block types are handled by the function... \c block_setup(...) ! The setup of the blocks and DOF types will be discussed in more detail later on.

\subsection subsidiary_preconditioners Master and Subsidiary Preconditioners

Consider the again the <a href="../../../preconditioners/lsc_navier_stokes/html/index.html"> Least-Squares Commutator (LSC) Navier-Stokes preconditioner</A>.
If we decide to approximate the \f$ {\bf F}\f$ block (the momentum block) by the diagonal blocks, we can pass the block diagonal preconditioner discussed in <a href="../../../mpi/distributed_general_purpose_block_preconditioners/html/index.html">(Distributed) General-Purpose Block Preconditioners</A> for the LSC preconditioner to use as a subsidiary preconditioner via the function \c set_f_preconditioner(...). We can do the same with the pressure solve with the function \c set_p_preconditioner(...). We refer to these preconditioners as subsidiary preconditioners. \c Oomph-lib's block preconditioning framework facilitates the the reuse of existing preconditioners as subsidiary preconditioners.


It is important to note that we do not need to consider the \b block structure of subsidiary block preconditioners when developing master preconditioners. However, the master preconditioner must know the DOF type ordering of the subsidiary preconditioner. For example, if the LSC preconditioner is a subsidiary preconditioner (as is the case of the FSI preconditioner), the FSI preconditioner must ensure that the last DOF type given to the LSC preconditioner is the pressure DOF type.


# TS: Start here

\section multi_poisson Simple preconditioner examples

In order to illustrate the usage of the Block Preconditioning
Framework we shall make use of a made up problem, named
multi-poisson, governed by the equations

\f[ 
(i+1) ( \frac{\partial^2 u_i}{\partial x_j^2} 
+ \beta \sum_{k=0}^{k<N} u_k )  = f_i(x_j) \ \ \ \ i=0,...,N-1
\f]

The linear system to be solved in the course of the Newton method,
\f[
{\bf J} \ \delta {\bf x} = -{\bf r},
\f]
has a \f$5 \times 5\f$  block structure implying that, following a re-numbering
of the unknowns, the matrix and the vectors can be written as
\f[
\label{diag_reordered_linear_system}
{\bf J} = 
\left(
\begin{array}{ccccc}
J_{11} & J_{12} & J_{13} & J_{14} & J_{15} \\
J_{21} & J_{22} & J_{23} & J_{24} & J_{25} \\
J_{31} & J_{32} & J_{33} & J_{34} & J_{35} \\
J_{41} & J_{42} & J_{43} & J_{44} & J_{45} \\
J_{51} & J_{52} & J_{53} & J_{54} & J_{55} \\
\end{array}
\right),
 \ \
\delta {\bf x} = 
\left(
\begin{array}{c}
\delta x_{1}  \\
\delta x_{2}  \\
\delta x_{3}  \\
\delta x_{4}  \\
\delta x_{5}  \\
\end{array}
\right)
 \ \mbox{ and } \ 
{\bf r} = 
\left(
\begin{array}{c}
r_{1}  \\
r_{2}  \\
r_{3}  \\
r_{4}  \\
r_{5}  \\
\end{array}
\right).
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
@E[eqn:orig_linear_system]@
\f]
We wish to solve this linear system by preconditioned Krylov subspace methods,
using a block preconditioner \f${\bf P}\f$ formed (formally) 
from the blocks of the original system matrix \f${\bf }J\f$. The
application of the preconditioner (typically once per iteration of the
Krylov solver) then requires the solution of linear systems of the form
\f$
{\bf P} {\bf y} = {\bf z},
\f$ 
for \f${\bf y}\f$. The preconditioning operation can also be written as
\f$
{\bf y} = {\bf P}^{-1} {\bf z}
\f$ 
where the operator \f${\bf P}^{-1}\f$ represents 
the application of the preconditioner to a vector \f${\bf z}\f$. 
Formally, the operator \f${\bf P}^{-1}\f$ represents the inverse of 
the matrix \f${\bf P}\f$ but its application may, of course, be performed  
approximately by another ``subsidiary'' preconditioner/inexact solver
e.g. by performing a small number of multigrid cycles, say.
(Note that we say ``formally'' because the preconditioner does not
actually have to be associated with a specific matrix -- it simply has
to act as a linear operator that ``turns \f${\bf z}\f$ into \f${\bf y}\f$'').

The block preconditioning framework facilitates the construction of a
block preconditioner from the entries of the matrix
\f${\bf J}\f$ which is assumed to represent the Jacobian matrix arising in the
Newton-based solution of a system of equations that is assembled
from ``block-preconditionable'' elements, i.e. elements
that implement the functions \c ndof_types() and
\c get_dof_numbers_for_unknowns(...), mentioned above. 
A specific block preconditioner must be derived from the
\c BlockPreconditioner base class and must implement two 
pure virtual member functions of the underlying \c Preconditioner
class:
- \c void \c Preconditioner::setup(): This function is
called once during the solution of a given linear system
by any of \c oomph-lib 's Krylov subspace solvers. It typically 
extracts a  certain number of blocks from the matrix \f${\bf J}\f$, possibly 
manipulates them, and performs any preliminary computations required 
to allow the rapid subsequent application of \f${\bf P}^{-1}\f$.
- \c void \c Preconditioner::preconditioner_solve(\f$\bf{z}\f$,\f$\bf{y}\f$):
This function applies \f${\bf P}^{-1}\f$ to the input argument
\f${\bf z}\f$ and returns \f${\bf y}\f$, typically using some data that has
been pre-computed in the \c setup() function.

We will discuss the implementation of these functions (and associated
capabilities of the block preconditioning framework)
in a number of increasingly complex block preconditioners
for the solution of the \f$5 \times 5\f$ linear system 
(@R[eqn:orig_linear_system]@). We stress that the purpose
of this exercise is not the development of particularly clever
preconditioners but simply an excuse to demonstrate the use of the
available ``machinery'', listed here:

- Extraction of selected blocks from the Jacobian.

- Off diagonal matrix vector products.

- Solving linear systems associated with these blocks by way of direct
 solver and/or subsidiary preconditioners. Including cases where the
 subsidiary preconditioners are block preconditioners themselves.

- Replacement and modification of selected blocks.

- Concatenation and Coarsening of several blocks, as well as covering
 when to use each.

These will be illustrated through the following preconditioners (and
associated sub-preconditioners):

- \ref diagonal

 - Extraction of selected blocks from the Jacobian. 

 - Exact solvers.

- \ref upper_triangular, making use of:

 - Extraction of selected blocks from the Jacobian.

 - Off diagonal matrix vector products.

 - Exact solvers.

- \ref two_plus_three, making use of:
 - Extraction of selected blocks from the Jacobian.
 - Exact solvers.

- \ref two_plus_three_upper_triangular, making use of:

 - Extraction of selected blocks from the Jacobian.

 - Off diagonal matrix vector products.

 - Exact solvers.

- \ref two_plus_three_upper_triangular_with_sub, making use of:

 - Extraction of selected blocks from the Jacobian.

 - Subsidiary block preconditioner.

 - Off diagonal matrix vector products.

 - Exact solvers.

- \ref two_plus_three_upper_triangular_with_replace, making use of:

 - Extraction of selected blocks from the Jacobian.

 - Replacement.

 - Concatenation.

 - Off diagonal matrix vector products.

 - Exact solvers.

 - Subsidiary block preconditioner.

- \ref coarse_two_plus_two_plus_one, making
 use of:

 - Subsidiary block preconditioner.

 - Exact solvers.

 - Extraction of selected blocks from the Jacobian.

 - Concatenation.
 
 - Coarsening.

\subsection diagonal Diagonal
\subsubsection diag_theory Theory
# TS: Include image

The simplest possible block preconditioner is a block-diagonal 
preconditioner, formed by retaining only the diagonal blocks of
\f${\bf J}\f$, so that
\f[
{\bf P} = 
\left(
\begin{array}{ccccc}
J_{11} & & & & \\
& J_{22} &  &  & \\
 & & J_{33} & & \\
 & & & J_{44} & \\
 &  & &  & J_{55} \\
\end{array}
\right).
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:

@E[eqn:diag_reordered_linear_system]@
\f]
The application of this preconditioner (i.e. the solution of the
linear system \f${\bf P} {\bf
  y} ={\bf z}\f$ for \f${\bf y}\f$) requires the solution of the 
five much smaller linear systems
\f[
\begin{array}{c}
{\bf J}_{11} \ {\bf y}_1 = {\bf z}_1, \\
{\bf J}_{22} \ {\bf y}_2 = {\bf z}_2, \\
{\bf J}_{33} \ {\bf y}_3 = {\bf z}_3, \\
{\bf J}_{44} \ {\bf y}_4 = {\bf z}_4, \\
{\bf J}_{55} \ {\bf y}_5 = {\bf z}_5, \\
\end{array}
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
@E[eqn:diag_prec]@
\f]
where we have assumed that the two vectors \f${\bf y}\f$ and \f${\bf z}\f$
are re-ordered into ``block vectors'' in the same way as 
the vectors \f$\delta {\bf x}\f$ and \f${\bf r}\f$ in 
(@R[eqn:orig_linear_system]@) "the original linear system" are re-ordered into
the ``block vectors'' in (@R[eqn:diag_reordered_linear_system]@).

The implementation of the preconditioning operations in 
(@R[eqn:diag_prec]@)  can naturally be subdivided into two
distinct \c setup() and \c preconditioner\_solve(...) phases.
Assuming that the linear systems in (@R[eqn:diag_prec]@) are solved exactly 
by a direct solver (an ``exact preconditioner'') that 
can pre-compute and store the LU decomposition of the diagonal matrix blocks,
the \c setup() phase involves the following operations
[text in square brackets refers to their \c oomph-lib specific 
implementation]:
- Set up any data structures/lookup tables that are required to 
extract matrix blocks from the original matrix
\f${\bf J}\f$ [by calling
the \c BlockPreconditioner::block\_setup() function]. 
- Extract the five diagonal blocks \f${\bf J}_{ii}\f$ 
(for \f$i=1,...,5\f$) [using the 
\c BlockPreconditioner::get\_block(...)} function.
- Compute and store the LU decomposition of the diagonal blocks
to allow the rapid solution of the systems \f${\bf J}_{ii} \ {\bf y}_i = 
{\bf z}_i\f$ (for \f$i=1,...,5\f$) during the \c preconditioner\_solve(...)
phase by back-substitution. [Note that, following the
computation of the LU decomposition, the diagonal matrix
blocks are longer required and can be deleted.]

Once the \c setup() phase has been completed, the solution of the linear
system \f${\bf P} {\bf y} = {\bf z}\f$ by the \c preconditioner\_solve(...) 
function involves the following steps:
- Extract the five ``block vectors'' \f${\bf z}_i\f$ (for \f$i=1,...,5\f$)
from the vector \f${\bf z}\f$ [using the 
\c BlockPreconditioner::get\_block\_vector(...) function].
- Solve the linear systems \f${\bf J}_{ii} \ {\bf y}_i = 
{\bf z}_i\f$ for the vectors \f${\bf y}_i\f$ (for \f$i=1,...,5\f$)  using 
the LU decomposition of the diagonal blocks \f${\bf J}_{ii}\f$ 
(for \f$i=1,...,5\f$) created during the \c setup() phase.
- Combine the five ``block vectors'' \f${\bf y}_i\f$ (for \f$i=1,...,5\f$)
to the full-length vector \f${\bf y}\f$ [using the 
\c BlockPreconditioner::return\_block\_vector(...) function].

\subsubsection diag_implementation Implementation as a BlockPreconditioner
Here is a sample implementation of the diagonal block preconditioner
as a class \c Simple, derived from the \c BlockPreconditioner base 
class. The class provides storage for the subsidiary preconditioners
that solve the linear systems associated with the diagonal blocks, 
implements the \c setup() and \c preconditioner\_solve(...)
functions, and provides a helper function \c clean\_up\_my\_memory()
which does what it says.

\dontinclude multi_poisson_block_preconditioners.h
\skipline start_of_diagonal_class
\until };


\subsubsection diag_setup The setup() function

The first thing that must be called at the beginning of every \c
setup(...) function is \c clean_up_my_memory(). This cleans up any
dynamically allocated memory.

\skip start_of_setup_for_simple
\until this->clean_up_my_memory();

Next, \c this->block_setup() is called, to set up any data structures
and/or lookup tables required to extract the desired blocks from the
Jacobian.

\skip //
\until this->block_setup();

Due to the class working on any sized square matrix, \c
this->nblock_types() is called and the result stored in \c
nblock_types, an \c unsigned, so we know the number of blocks to
iterate over. The \c private data member \c Diagonal_block_preconditioner_pt
is resized to \c nblock_types and then looped over, with each element
being assigned a \c new preconditioner (inexact solver). In this case
we have used SuperLU, an inbuilt preconditioner type that applies an
LU decomposition and find the exact solution of whatever block is
handed to it.

\skip //
\until }

Each preconditioner then needs to be set up itself. This requires
getting a block from the Jacobian, supplied via the function 
\c get\_block(i,j,block) which returns a deep copy of the required
matrix, from the (i,j) block of the Jacobian, to the supplied
\c CRDoubleMatrix, \c block. The \c block may then go out of scope, as
a deep copy is made of whatever elements are necessary from the
subsidiary preconditioner.

\skip //
\until }


\subsubsection diag_solve The preconditioner_solve() function

In order to solve via the sub-preconditioners, the right hand side
vector is required to be split into blocks matching that used by the
preconditioners. This is done automatically for you by
\c this->get_block_vectors(r,block_r). \c r, is given to you as an
argument of the \c  preconditioner_solve(...) function when it is
called, \c block_r must be created beforehand, but need not be sized.

\skip //======
\until this->get_block

The associated solution blocks \c block_z are created similarly to \c block_r,
however they require initialisation to size \c nblock_types, which is
found similarly to in the \c setup(...) function. The \c
Diagonal_block_preconditioner_pt are looped over and their associated \c
preconditioner_solve(...) called, supplying the necessary elements
from \c block_r and \c block_z.

\skip //
\until }

Finally the solutions in \c block_z are returned via \c
this->return_block_vectors(block_z,z). Which places the results back
into the \c DoubleVector \c z.

\skip //
\until ;

\subsubsection diag_clean The clean_up_my_memory() function
The clean up memory functions purpose is to delete any existing
private data (and null it for safety purposes).

\skip //
\until // End of clean_up_my_memory function.

The reason that this is required is the preconditioner is called as
part of a linear solver program and may be used multiple times for
various nonlinear solves over the course of the program. An obvious
example of this is a time dependent problem. 

Therefore to stop the build-up of unnecessary memory \c
clean_up_my_memory() is called twice. Once at the beginning of 
\c setup() to avoid leakage if the preconditioner is reused, and the
second time is in the destructor (\c ~Simple()) to avoid memory leaks
if potential loops create and destroy the preconditioner, either
through \c new and \c delete or the preconditioner going out of scope.

\subsubsection diag_comments Comments

- In \ref diag_setup

 - \c this->blocksetup() is called with no arguments. This is because
   the correspondence between the DoFs and the blocks is merely the
   identity matrix; however in more complicated cases, such as in \ref
   one_plus_four, this may not be the desired arrangement and arguments
   may be supplied. 

 - \c get_block(i,j,block) takes account of whether the preconditioner
   you are in is a subsidiary preconditioner, such as is the the case
   in \ref coarse_one_plus_two_plus_two_with_sub_and_replace, then it
   will take account of replacement in the master preconditioner.

- In \ref diag_solve

 - \c this->get_block_vectors(r,block_r) is used to get the vector 
   \c r, however cases involving concatenation or coarsening require
   calling different versions of the \c get_ functions.

  - The same applies to \c return_; additionally unless you are using
    subsidiary preconditioners your \c return_ should always match your 
    \c get_, in this case both are \c block_vectors(...).

\subsection upper_triangular Upper Triangular
\subsubsection upper_triangular_theory Theory
# TS: Include image
Another possible preconditioner is the upper triangular
preconditioner, formed by retaining only the blocks in the upper right
hand side of \f${\bf J}\f$, including the diagonals.
\f[
{\bf P} = 
\left(
\begin{array}{ccccc}
J_{11} & J_{12} & J_{13} & J_{14} & J_{15} \\
& J_{22} &  J_{23} &  J_{24} & J_{25} \\
 & & J_{33} & J_{34} & J_{35} \\
 & & & J_{44} & J_{45} \\
 &  & &  & J_{55} \\
\end{array}
\right).
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
@E[eqn:upper_triangular_reordered_linear_system]@
\f]
The application of this preconditioner (i.e. the solution of the
linear system \f${\bf P} {\bf
  y} ={\bf z}\f$ for \f${\bf y}\f$) requires the solution of the 
five much smaller linear systems
\f[
\begin{array}{c}
{\bf J}_{11} \ {\bf y}_1 = {\bf z}_1 - {\bf J}_{15} \ {\bf y}_5 - {\bf J}_{14} \ {\bf y}_4 - {\bf J}_{13} \ {\bf y}_3 - {\bf J}_{12} \ {\bf y}_2, \\
{\bf J}_{22} \ {\bf y}_2 = {\bf z}_2 - {\bf J}_{25} \ {\bf y}_5 - {\bf J}_{24} \ {\bf y}_4 - {\bf J}_{23} \ {\bf y}_3, \\
{\bf J}_{33} \ {\bf y}_3 = {\bf z}_3 - {\bf J}_{35} \ {\bf y}_5 - {\bf J}_{34} \ {\bf y}_4, \\
{\bf J}_{44} \ {\bf y}_4 = {\bf z}_4 - {\bf J}_{45} \ {\bf y}_5, \\
{\bf J}_{55} \ {\bf y}_5 = {\bf z}_5, \\
\end{array}
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
@E[eqn:upper_triangular_prec]@
\f]
where we have assumed that the two vectors \f${\bf y}\f$ and \f${\bf z}\f$
are re-ordered into ``block vectors'' in the same way as 
the vectors \f$\delta {\bf x}\f$ and \f${\bf r}\f$ in 
(@R[eqn:orig_linear_system]@) "the original linear system" are re-ordered into
the ``block vectors'' in
(@R[eqn:upper_triangular_reordered_linear_system]@).

The implementation of the preconditioning operations in 
(@R[eqn:upper_triangular_prec]@)  can naturally be subdivided into two
distinct \c setup() and \c preconditioner\_solve(...) phases.
Assuming that the linear systems in (@R[eqn:upper_triangular_prec]@)
are solved exactly by a direct solver (an ``exact preconditioner'')
that can pre-compute and store the LU decomposition of the diagonal
matrix blocks, the \c setup() phase involves the following operations
[text in square brackets refers to their \c oomph-lib specific 
implementation]:
- Set up any data structures/lookup tables that are required to 
extract matrix blocks from the original matrix
\f${\bf J}\f$ [by calling
the \c BlockPreconditioner::block\_setup() function]. 
- Extract the five diagonal blocks \f${\bf J}_{ii}\f$ 
(for \f$i=1,...,5\f$) [using the 
\c BlockPreconditioner::get\_block(...)} function.
- Compute and store the LU decomposition of the diagonal blocks
to allow the rapid solution of the systems \f${\bf J}_{ii} \ {\bf y}_i = 
{\bf z}_i\f$ (for \f$i=1,...,5\f$) during the \c preconditioner\_solve(...)
phase by back-substitution. [Note that, following the
computation of the LU decomposition, the diagonal matrix
blocks are longer required and can be deleted.]
- Extract the off diagonal blocks from \f${\bf J}\f$  [and store them
in a \c DenseMatrix of template type \c MatrixVectorProduct. This is
used to calculate the product between the off diagonal blocks and the
relevant \f${\bf y}_i\f$. Using the 
\c setup_matrix_vector_product(...) function. Note that, following the
setup, the off-diagonal matrix blocks are longer required and can be
deleted.]

\subsubsection upper_triangular_implementation Implementation as a BlockPreconditioner
Here is a sample implementation of the upper triangular block preconditioner
as a class \c UpperTriangular, derived from the \c BlockPreconditioner base 
class. The class provides storage for the subsidiary preconditioners
that solve the linear systems associated with the diagonal blocks, and
the \c MatrixVectorProduct's used to calculate the effect of the off
diagonal elements of \f${\bf J}\f$ on the residual; implements the \c
setup() and \c preconditioner\_solve(...) functions, and provides a
helper function \c clean\_up\_my\_memory() which does what it says.

\dontinclude multi_poisson_block_preconditioners.h
\skipline start_of_upper_triangular_class
\until };

\subsubsection upper_triangular_setup The setup() function

The first thing that must be called at the beginning of every \c
setup(...) function is \c clean_up_my_memory(). This cleans up any
dynamically allocated memory.

\skip start_of_setup_for_upper_triangular
\until this->clean_up_my_memory();

Next, \c this->block_setup() is called, to set up any data structures
and/or lookup tables required to extract the desired blocks from the
Jacobian.

\skip //
\until this->block_setup();

Due to the class working on any sized square matrix, \c
this->nblock_types() is called and the result stored in \c
nblock_types, an \c unsigned, so we know the number of blocks to
iterate over. The storage for the diagonal preconditioners and the off
diagonal matrix products are then resized appropriately.

\skip //
\until Block_preconditioner_pt.resize(nblock_types);

The subsidiary preconditioners are then assigned a \c new
preconditioner (inexact solver). In this case
we have used SuperLU, an inbuilt preconditioner type that applies an
LU decomposition and find the exact solution of whatever block is
handed to it. Inside the same loop the preconditioners are then set
up. This requires getting a block from the Jacobian, supplied via the
function  \c get\_block(i,j,block) which returns a deep copy of the
required matrix, from the (i,j) block of the Jacobian, to the supplied
\c CRDoubleMatrix, \c block. The \c block may then go out of scope, as
a deep copy is made of whatever elements are necessary from the
subsidiary preconditioner.

Similar logic applies to the \c Off_diagonal_matrix_vector_products.

\skip //
\until // End for loop over i

\subsubsection upper_triangular_solve The preconditioner_solve() function

In order to solve via the sub-preconditioners, the right hand side
vector is required to be split into blocks matching that used by the
preconditioners. This is done automatically for you by
\c this->get_block_vectors(r,block_r). \c r, is given to you as an
argument of the \c  preconditioner_solve(...) function when it is
called, \c block_r must be created beforehand, but need not be sized.

\skip //======
\until this->get_block

The associated solution blocks \c block_z are created similarly to \c block_r,
however they require initialisation to size \c nblock_types, which is
found similarly to in the \c setup(...) function. 

\skip //
\until Vector<DoubleVector> block_z(n_block);

Due to the off diagonal elements the RHS, \c block_r, is required to
be changed via back substitution of the previous solutions. As the
preconditioner is upper diagonal the last element must be iterated
over first to allow the result from its \c  preconditioner_solve(...)
to be used in the next back substitution.

\skip //
\until // End for over i

Finally the solutions in \c block_z are returned via \c
this->return_block_vectors(block_z,z). Which places the results back
into the \c DoubleVector \c z.

\skip //
\until ;

\subsubsection upper_triangular_clean The clean_up_my_memory() function
The clean up memory functions purpose is to delete any existing
private data (and null it for safety purposes).

\skip //
\until // End of clean_up_my_memory function.

\subsection two_plus_three Two Plus Three
\subsubsection two_plus_three_theory Theory

In this example we retain only the blocks belonging to the 1st and 2nd
dofs, and the blocks beloing to the 3rd, 4th and 5th dofs; such that

\f${\bf J}\f$, so that
\f[
{\bf P} = 
\left(
\begin{array}{ccccc}
J_{11} & J_{12} & & & \\
J_{21} & J_{22} &  &  & \\
 & & J_{33} & J_{34} & J_{35} \\
 & & J_{43} & J_{44} & J_{45} \\
 & & J_{53} & J_{54}  & J_{55} \\
\end{array}
\right).
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
@E[eqn:two_plus_three_reordered_linear_system]@
\f]
The application of this preconditioner (i.e. the solution of the
linear system \f${\bf P} {\bf
  y} ={\bf z}\f$ for \f${\bf y}\f$) requires the solution of the 
two smaller linear systems
\f[
\begin{array}{c}
\left(
\begin{array}{cc}
J_{11} & J_{12} \\
J_{21} & J_{22} \\
\end{array}
\right) \left(
\begin{array}{c}
y_1 \\
y_2 \\
\end{array}
\right) = \left(
\begin{array}{c}
z_1 \\ 
z_2 \\
\end{array}
\right)
\\
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
@E[eqn:two_plus_three_prec]@
\\
\left(
\begin{array}{ccc}
J_{33} & J_{34} & J_{35} \\
J_{43} & J_{44} & J_{45} \\
J_{53} & J_{54} & J_{55} \\
\end{array}
\right) \left(
\begin{array}{c}
y_3 \\
y_4 \\
y_5 \\
\end{array}
\right) = \left(
\begin{array}{c}
z_3 \\ 
z_4 \\
z_5 \\
\end{array}
\right)
\end{array}
\f]
where we have assumed that the two vectors \f${\bf y}\f$ and \f${\bf z}\f$
are re-ordered into ``block vectors'' in the same way as 
the vectors \f$\delta {\bf x}\f$ and \f${\bf r}\f$ in 
(@R[eqn:orig_linear_system]@) "the original linear system" are re-ordered into
the ``block vectors'' in
(@R[eqn:two_plus_three_reordered_linear_system]@).
The implementation of the preconditioning operations in 
(@R[eqn:diag_prec]@)  can naturally be subdivided into two
distinct \c setup() and \c preconditioner\_solve(...) phases.
Assuming that the linear systems in (@R[eqn:two_plus_three_prec]@) are
solved exactly by a direct solver (an ``exact preconditioner'') that 
can pre-compute and store the LU decomposition of the diagonal matrix blocks,
the \c setup() phase involves the following operations
[text in square brackets refers to their \c oomph-lib specific 
implementation]:
- Set up any data structures/lookup tables that are required to 
extract matrix blocks from the original matrix
\f${\bf J}\f$ [by calling
the \c BlockPreconditioner::block\_setup(...) function]. 
- Extract the two diagonal blocks [using the 
\c BlockPreconditioner::get\_block(...)} function.
- Compute and store the LU decomposition of the diagonal blocks
to allow the rapid solution of the systems during the
 \c preconditioner\_solve(...)
phase by back-substitution. [Note that, following the
computation of the LU decomposition, the diagonal matrix
blocks are longer required and can be deleted.]

Once the \c setup() phase has been completed, the solution of the linear
system \f${\bf P} {\bf y} = {\bf z}\f$ by the \c preconditioner\_solve(...) 
function involves the following steps:
- Extract the two ``block vectors'' \f${\bf z}_i\f$ (for \f$i=1,2\f$)
from the vector \f${\bf z}\f$ [using the 
\c BlockPreconditioner::get\_block\_vector(...) function].
- Solve the linear systems \f${\bf J}_{ii} \ {\bf y}_i = 
{\bf z}_i\f$ for the vectors \f${\bf y}_i\f$ (for \f$i=1,2\f$)  using 
the LU decomposition of the diagonal blocks \f${\bf J}_{ii}\f$ 
(for \f$i=1,2\f$) created during the \c setup() phase.
- Combine the two ``block vectors'' \f${\bf y}_i\f$ (for \f$i=1,...,5\f$)
to the full-length vector \f${\bf y}\f$ [using the 
\c BlockPreconditioner::return\_block\_vector(...) function].

\subsubsection two_plus_three_implementation Implementation as a BlockPreconditioner

\subsubsection two_plus_three_setup The setup() function

The first thing that must be called at the beginning of every \c
setup(...) function is \c clean_up_my_memory(). This cleans up any
dynamically allocated memory.

\skip start_of_setup_for_two_plus_three
\until this->clean_up_my_memory();

Next we check that the number of degrees of freedom is 5, as the
preconditioner is designed to only work for that number. The check is
only necessary if \c OOMPH-LIB is complied with the \c PARANOID flag,
and as such is inside an \c #ifdef statement.

\skip #ifdef
\until #endif

Now that we have know we 5 dof types we create a \c Vector of \c unsigned to
map the dofs to the blocks. This map is passed to block setup so that
\c get_block(...) will work in the new scheme.

\skip //
\until this->block_setup(dof_to_block_map);

The preconditioners are then created and the appropriate blocks from
\f${\bf J}\f$ are passed to them.

\skip // Create the subsidiary preconditioners
\until // End of setup

\subsubsection two_plus_three_solve The preconditioner_solve() function

In order to solve via the sub-preconditioners, the right hand side
vector is required to be split into blocks matching that used by the
preconditioners. This is done automatically for you by
\c this->get_block_vectors(r,block_r). \c r, is given to you as an
argument of the \c  preconditioner_solve(...) function when it is
called, \c block_r must be created beforehand, but need not be sized.

The \c this->get_block_vectors function is aware of the blocking
scheme, that was created in the \c setup(...) function, and therefore
requires no extra arguments.

\skip //======
\until this->get_block

The associated solution blocks \c block_z are created similarly to \c block_r,
however they require initialisation to size \c nblock_types, which is
found similarly to in the \c setup(...) function.

\skip //
\until Vector<DoubleVector> block_z(n_block);

The two systems are then solved.

\skip //
\until block_z[1])

Finally the computed \c block_z are returned to the original \c z. 

\skip //
\until this->

\subsubsection two_plus_three_clean The clean_up_my_memory() function

The clean up memory functions purpose is to delete any existing
private data (and null it for safety purposes).

\skip //
\until // End of clean_up_my_memory function.

The reason that this is required is the preconditioner is called as
part of a linear solver program and may be used multiple times for
various nonlinear solves over the course of the program. An obvious
example of this is a time dependent problem. 

Therefore to stop the build-up of unnecessary memory \c
clean_up_my_memory() is called twice. Once at the beginning of 
\c setup() to avoid leakage if the preconditioner is reused, and the
second time is in the destructor (\c ~Simple()) to avoid memory leaks
if potential loops create and destroy the preconditioner, either
through \c new and \c delete or the preconditioner going out of scope.

\subsection two_plus_three_upper_triangular Two plus three upper triangular
\subsubsection two_plus_three_upper_triangular_theory Theory
# TS: Include image

In this example we retain only the blocks belonging to the 1st and 2nd
dofs, and the blocks beloing to the 3rd, 4th and 5th dofs, along with
the upper diagonals; such that
\f[
{\bf P} = 
\left(
\begin{array}{ccccc}
J_{11} & J_{12} & J_{13} & J_{14} & J_{15} \\
J_{21} & J_{22} & J_{13} & J_{14} & J_{15} \\
 & & J_{33} & J_{34} & J_{35} \\
 & & J_{43} & J_{44} & J_{45} \\
 & & J_{53} & J_{54} & J_{55} \\
\end{array}
\right).
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
@E[eqn:two_plus_three_upper_triangular_reordered_linear_system]@
\f]
The application of this preconditioner (i.e. the solution of the
linear system \f${\bf P} {\bf
  y} ={\bf z}\f$ for \f${\bf y}\f$) requires the solution of the 
two smaller linear systems
\f[
\begin{array}{c}
\left(
\begin{array}{cc}
J_{11} & J_{12} \\
J_{21} & J_{22} \\
\end{array}
\right) \left(
\begin{array}{c}
y_1 \\
y_2 \\
\end{array}
\right) = \left(
\begin{array}{c}
z_1 \\ 
z_2 \\
\end{array}
\right) - \left(
\begin{array}{ccc}
J_{13} & J_{14} & J_{15} \\
J_{23} & J_{24} & J_{25}  \\
\end{array}
\right) \left(
\begin{array}{c}
y_3 \\
y_4 \\
y_5 \\
\end{array}
\right)
\\
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
@E[eqn:two_plus_three_upper_triangular_prec]@
\\
\left(
\begin{array}{ccc}
J_{33} & J_{34} & J_{35} \\
J_{43} & J_{44} & J_{45} \\
J_{53} & J_{54} & J_{55} \\
\end{array}
\right) \left(
\begin{array}{c}
y_3 \\
y_4 \\
y_5 \\
\end{array}
\right) = \left(
\begin{array}{c}
z_3 \\ 
z_4 \\
z_5 \\
\end{array}
\right)
\end{array}
\f]
where we have assumed that the two vectors \f${\bf y}\f$ and \f${\bf z}\f$
are re-ordered into ``block vectors'' in the same way as 
the vectors \f$\delta {\bf x}\f$ and \f${\bf r}\f$ in 
(@R[eqn:orig_linear_system]@) "the original linear system" are re-ordered into
the ``block vectors'' in
(@R[eqn:two_plus_three_upper_triangular_reordered_linear_system]@).
The implementation of the preconditioning operations in 
(@R[eqn:diag_prec]@)  can naturally be subdivided into two
distinct \c setup() and \c preconditioner\_solve(...) phases.
Assuming that the linear systems in (@R[eqn:two_plus_three_prec]@) are
solved exactly by a direct solver (an ``exact preconditioner'') that 
can pre-compute and store the LU decomposition of the diagonal matrix blocks,
the \c setup() phase involves the following operations
[text in square brackets refers to their \c oomph-lib specific 
implementation]:
- Set up any data structures/lookup tables that are required to 
extract matrix blocks from the original matrix
\f${\bf J}\f$ [by calling
the \c BlockPreconditioner::block\_setup(...) function]. 
- Extract the two diagonal blocks [using the 
\c BlockPreconditioner::get\_block(...)} function.
- Compute and store the LU decomposition of the diagonal blocks
to allow the rapid solution of the systems during the
 \c preconditioner\_solve(...)
phase by back-substitution. [Note that, following the
computation of the LU decomposition, the diagonal matrix
blocks are longer required and can be deleted.]
- Extract the off diagonal blocks from J [and store them in a \c
DenseMatrix of template type \c Matrix-VectorProduct . This is used to
calculate the product between the off diagonal blocks and the relevant
\c y_i . Using the \c setup_matrix_vector_product(...) function. Note
that, following the setup, the off-diagonal matrix blocks are longer
required and can be deleted.]

Once the \c setup() phase has been completed, the solution of the linear
system \f${\bf P} {\bf y} = {\bf z}\f$ by the \c preconditioner\_solve(...) 
function involves the following steps:
- Extract the two ``block vectors'' \f${\bf z}_i\f$ (for \f$i=1,2\f$)
from the vector \f${\bf z}\f$ [using the 
\c BlockPreconditioner::get\_block\_vector(...) function].
- Solve the linear systems \f${\bf J}_{ii} \ {\bf y}_i = 
{\bf z}_i\f$ for the vectors \f${\bf y}_i\f$ (for \f$i=1,2\f$)  using 
the LU decomposition of the diagonal blocks \f${\bf J}_{ii}\f$ 
(for \f$i=1,2\f$) created during the \c setup() phase. using the
results from the previous step, backsubstitute 
- Combine the two ``block vectors'' \f${\bf y}_i\f$ (for \f$i=1,...,5\f$)
to the full-length vector \f${\bf y}\f$ [using the 
\c BlockPreconditioner::return\_block\_vector(...) function].



\subsubsection two_plus_three_upper_triangular_implementation Implementation as a BlockPreconditioner

\subsubsection two_plus_three_upper_triangular_setup The setup() function

The first thing that must be called at the beginning of every \c
setup(...) function is \c clean_up_my_memory(). This cleans up any
dynamically allocated memory.

\skip start_of_setup_for_two_plus_three_upper_triangular
\until this->clean_up_my_memory();

Next we check that the number of degrees of freedom is 5, as the
preconditioner is designed to only work for that number. The check is
only necessary if \c OOMPH-LIB is complied with the \c PARANOID flag,
and as such is inside an \c #ifdef statement.

\skip //
\until #endif

Now that we have 5 dof types we create a \c Vector of \c unsigned to
map the dofs to the blocks. This map is passed to block setup so that
\c get_block(...) will work in the new scheme.

\skip //
\until this->block_setup(dof_to_block_map);

The preconditioners are then created and the \c DenseMatrix for the
off diagonal vector products is resized.

\skip // Create the subsidiary preconditioners
\until Off_diag

We then call the preconditioner's \c setup(...) functions, passing in
a reference to the extracted \c block, remembering that we have
changed the scheme from the identity matrix with \c block_setup(...).

\skip // 
\until }
\until }

Finally we setup the off diagonal vector products, again recalling the
new block scheme.

\skip //
\until }

\subsubsection two_plus_three_upper_triangular_solve The preconditioner_solve() function

In order to solve via the sub-preconditioners, the right hand side
vector is required to be split into blocks matching that used by the
preconditioners. This is done automatically for you by
\c this->get_block_vectors(r,block_r). \c r, is given to you as an
argument of the \c  preconditioner_solve(...) function when it is
called, \c block_r must be created beforehand, but need not be sized.

The \c this->get_block_vectors function is aware of the blocking
scheme, that was created in the \c setup(...) function, and therefore
requires no extra arguments.

\skip //======
\until this->get_block

The associated solution blocks \c block_z are created similarly to \c block_r,
however they require initialisation to size \c nblock_types, which is
found similarly to in the \c setup(...) function.

\skip //
\until Vector<DoubleVector> block_z(n_block);

The (1,1) system is then solved, so that it may be back substituted to
change the RHS, \c r, for the solution to the (0,0) block.

\skip //
\until block_z[0])

Finally the computed \c block_z are returned to the original \c z. 

\skip //
\until this->

\subsubsection two_plus_three_upper_triangular_clean The clean_up_my_memory() function

The clean up memory functions purpose is to delete any existing
private data (and null it for safety purposes).

\skip //
\until // End of clean_up_my_memory function.

The reason that this is required is the preconditioner is called as
part of a linear solver program and may be used multiple times for
various nonlinear solves over the course of the program. An obvious
example of this is a time dependent problem. 

Therefore to stop the build-up of unnecessary memory \c
clean_up_my_memory() is called twice. Once at the beginning of 
\c setup() to avoid leakage if the preconditioner is reused, and the
second time is in the destructor (\c ~Simple()) to avoid memory leaks
if potential loops create and destroy the preconditioner, either
through \c new and \c delete or the preconditioner going out of scope.


\subsection two_plus_three_upper_triangular_with_sub Two plus three upper triangular with subsidiary
\subsubsection two_plus_three_upper_triangular_with_sub_theory Theory
# TS: Include image

In this example we retain only the blocks belonging to the 1st and 2nd
dofs, and the blocks beloing to the 3rd, 4th and 5th dofs, along with
the upper diagonals; such that
\f[
{\bf P} = 
\left(
\begin{array}{ccccc}
J_{11} & J_{12} & J_{13} & J_{14} & J_{15} \\
J_{21} & J_{22} & J_{13} & J_{14} & J_{15} \\
 & & J_{33} & J_{34} & J_{35} \\
 & & J_{43} & J_{44} & J_{45} \\
 & & J_{53} & J_{54} & J_{55} \\
\end{array}
\right).
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
@E[eqn:two_plus_three_upper_triangular_with_sub_reordered_linear_system]@
\f]
The application of this preconditioner (i.e. the solution of the
linear system \f${\bf P} {\bf
  y} ={\bf z}\f$ for \f${\bf y}\f$) requires the solution of the 
two smaller linear systems
\f[
\begin{array}{c}
\left(
\begin{array}{cc}
J_{11} & J_{12} \\
J_{21} & J_{22} \\
\end{array}
\right) \left(
\begin{array}{c}
y_1 \\
y_2 \\
\end{array}
\right) = \left(
\begin{array}{c}
z_1 \\ 
z_2 \\
\end{array}
\right) - \left(
\begin{array}{ccc}
J_{13} & J_{14} & J_{15} \\
J_{23} & J_{24} & J_{25}  \\
\end{array}
\right) \left(
\begin{array}{c}
y_3 \\
y_4 \\
y_5 \\
\end{array}
\right)
\\
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
@E[eqn:two_plus_three_upper_triangular_with_sub_prec]@
\\
\left(
\begin{array}{ccc}
J_{33} & J_{34} & J_{35} \\
J_{43} & J_{44} & J_{45} \\
J_{53} & J_{54} & J_{55} \\
\end{array}
\right) \left(
\begin{array}{c}
y_3 \\
y_4 \\
y_5 \\
\end{array}
\right) = \left(
\begin{array}{c}
z_3 \\ 
z_4 \\
z_5 \\
\end{array}
\right)
\end{array}
\f]
where we have assumed that the two vectors \f${\bf y}\f$ and \f${\bf z}\f$
are re-ordered into ``block vectors'' in the same way as 
the vectors \f$\delta {\bf x}\f$ and \f${\bf r}\f$ in 
(@R[eqn:orig_linear_system]@) "the original linear system" are re-ordered into
the ``block vectors'' in
(@R[eqn:two_plus_three_upper_triangular_with_sub_reordered_linear_system]@).

The systems in (@R[eqn:two_plus_three_upper_triangular_with_sub_reordered_linear_system]@) are
then solved by subsidiary preconditioners themselves. The subsidiary
preconditioners do upper triangular solves changing the systems respectively
to
\f[
\begin{array}{c}
\left(
\begin{array}{cc}
J_{11} & J_{12} \\
 & J_{22} \\
\end{array}
\right) \left(
\begin{array}{c}
y_1 \\
y_2 \\
\end{array}
\right) = \left(
\begin{array}{c}
z_1 \\ 
z_2 \\
\end{array}
\right) - \left(
\begin{array}{ccc}
J_{13} & J_{14} & J_{15} \\
J_{23} & J_{24} & J_{25}  \\
\end{array}
\right) \left(
\begin{array}{c}
y_3 \\
y_4 \\
y_5 \\
\end{array}
\right)
\\
\left(
\begin{array}{ccc}
J_{33} & J_{34} & J_{35} \\
 & J_{44} & J_{45} \\
 &  & J_{55} \\
\end{array}
\right) \left(
\begin{array}{c}
y_3 \\
y_4 \\
y_5 \\
\end{array}
\right) = \left(
\begin{array}{c}
z_3 \\ 
z_4 \\
z_5 \\
\end{array}
\right)
\end{array}
\f]

The implementation of the preconditioning operations in 
(@R[eqn:diag_prec]@)  can naturally be subdivided into two
distinct \c setup() and \c preconditioner\_solve(...) phases.
Assuming that the linear systems in (@R[eqn:two_plus_three_prec]@) are
solved exactly by a direct solver (an ``exact preconditioner'') that 
can pre-compute and store the LU decomposition of the diagonal matrix blocks,
the \c setup() phase involves the following operations
[text in square brackets refers to their \c oomph-lib specific 
implementation]:
- Set up any data structures/lookup tables that are required to 
extract matrix blocks from the original matrix
\f${\bf J}\f$ [by calling
the \c BlockPreconditioner::block\_setup(...) function]. 
- Extract the two diagonal blocks [using the 
\c BlockPreconditioner::get\_block(...)} function.
- Pass the diagonal blocks to the subsidiary preconditioners, and call
their \c setup(...) functions.
- Extract the off diagonal blocks from J [and store them in a \c
DenseMatrix of template type \c Matrix-VectorProduct . This is used to
calculate the product between the off diagonal blocks and the relevant
\c y_i . Using the \c setup_matrix_vector_product(...) function. Note
that, following the setup, the off-diagonal matrix blocks are longer
required and can be deleted.]

Once the \c setup() phase has been completed, the solution of the linear
system \f${\bf P} {\bf y} = {\bf z}\f$ by the \c preconditioner\_solve(...) 
function involves the following steps:
- Extract the two ``block vectors'' \f${\bf z}_i\f$ (for \f$i=1,2\f$)
from the vector \f${\bf z}\f$ [using the 
\c BlockPreconditioner::get\_block\_vector(...) function].
- Solve the linear systems \f${\bf J}_{ii} \ {\bf y}_i = 
{\bf z}_i\f$ for the vectors \f${\bf y}_i\f$ (for \f$i=1,2\f$)  using 
the LU decomposition of the diagonal blocks \f${\bf J}_{ii}\f$ 
(for \f$i=1,2\f$) created during the \c setup() phase. using the
results from the previous step, backsubstitute 
- Combine the two ``block vectors'' \f${\bf y}_i\f$ (for \f$i=1,2\f$)
to the full-length vector \f${\bf y}\f$ [using the 
\c BlockPreconditioner::return\_block\_vector(...) function].

\subsubsection two_plus_three_upper_triangular_with_sub_implementation Implementation as a BlockPreconditioner

\subsubsection two_plus_three_upper_triangular_with_sub_setup The setup() function


The first thing that must be called at the beginning of every \c
setup(...) function is \c clean_up_my_memory(). This cleans up any
dynamically allocated memory.

\skip start_of_setup_for_two_plus_three_upper_triangular
\until this->clean_up_my_memory();

Next we check that the number of degrees of freedom is 5, as the
preconditioner is designed to only work for that number. The check is
only necessary if \c OOMPH-LIB is complied with the \c PARANOID flag,
and as such is inside an \c #ifdef statement.

\skip //
\until #endif

Now that we have 5 dof types we create a \c Vector of \c unsigned to
map the dofs to the blocks. This map is passed to block setup so that
\c get_block(...) will work in the new scheme.

\skip //
\until this->block_setup(dof_to_block_map);

The preconditioners are then created, as they are block
preconditioners themselves they require turning into subsidiary
preconditioners. This takes a map of the dofs in the subsidiary
preconditioner to the dofs in the master preconditioner.

\skip // Create the subsidiary preconditioners
\until block_prec_pt->setup(this->matrix_pt());

The off diagonal matrix vector products are then resized appropriately
and created.

\skip //
\until }
\until }

\subsubsection two_plus_three_upper_triangular_with_sub_solve The preconditioner_solve() function

Firstly the (1,1) block is solved, so that it can be back substituted
in later. This is done by passing the \c r and \c z \c DoubleVectors
to it, from which it extracts the required blocks automatically.

\skip //
\until Second_subsidiary_preconditioner_pt->preconditioner_solve(r,z);

The RHS then needs to be gotten, so that it can be used for the off
diagonal matrix vector product calculations, this is done with the \c
get_block_vectors(...) functions. The \c z are taken in a similar
fashion and then the off diagonal calculation is preformed.

\skip //
\until block_r[0] -= temp; 

As the RHS has been modified, a new \c DoubleVector needs to be
created to pass to the \c first_subsidiary_preconditioner_pt. This is
then passed to the preconditioner, which returns the relevant results.

\skip //
\until }

\subsubsection two_plus_three_upper_triangular_with_sub_clean The clean_up_my_memory() function

The clean up memory functions purpose is to delete any existing
private data (and null it for safety purposes).

\skip //
\until // End of clean_up_my_memory function.

The reason that this is required is the preconditioner is called as
part of a linear solver program and may be used multiple times for
various nonlinear solves over the course of the program. An obvious
example of this is a time dependent problem. 

Therefore to stop the build-up of unnecessary memory \c
clean_up_my_memory() is called twice. Once at the beginning of 
\c setup() to avoid leakage if the preconditioner is reused, and the
second time is in the destructor (\c ~Simple()) to avoid memory leaks
if potential loops create and destroy the preconditioner, either
through \c new and \c delete or the preconditioner going out of scope.


\subsection two_plus_three_upper_triangular_with_replace Two plus three upper triangular with replacement

\subsubsection two_plus_three_upper_triangular_with_replace_theory Theory

In this example we retain only the blocks belonging to the 1st and 2nd
dofs, and the blocks beloing to the 3rd, 4th and 5th dofs, then
replace any dof level blocks that are not on the diagonals with a
replacement block, \f$R_{ij}\f$; such that

\f${\bf J}\f$, so that
\f[
{\bf P} = 
\left(
\begin{array}{ccccc}
J_{11} & R_{12} & R_{13} & R_{14} & R_{15} \\
R_{21} & J_{22} & R_{23} & R_{24} & R_{25} \\
 & & J_{33} & R_{34} & R_{35} \\
 & & R_{43} & J_{44} & R_{45} \\
 & & R_{53} & R_{54} & J_{55} \\
\end{array}
\right).
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
@E[eqn:two_plus_three_reordered_linear_system]@
\f]
The application of this preconditioner (i.e. the solution of the
linear system \f${\bf P} {\bf
  y} ={\bf z}\f$ for \f${\bf y}\f$) requires the solution of the 
two smaller linear systems
\f[
\begin{array}{c}
\left(
\begin{array}{cc}
J_{11} & R_{12} \\
R_{21} & J_{22} \\
\end{array}
\right) \left(
\begin{array}{c}
y_1 \\
y_2 \\
\end{array}
\right) = \left(
\begin{array}{c}
z_1 \\ 
z_2 \\
\end{array}
\right) - \left(
\begin{array}{ccc}
R_{13} & R_{14} & R_{15} \\
R_{23} & R_{24} & R_{25} \\
\end{array}
\right) \left(
\begin{array}{c}
z_3 \\
z_4 \\
z_5 \\
\end{array}
\right)
\\
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
@E[eqn:two_plus_three_prec]@
\\
\left(
\begin{array}{ccc}
J_{33} & R_{34} & R_{35} \\
R_{43} & J_{44} & R_{45} \\
R_{53} & R_{54} & J_{55} \\
\end{array}
\right) \left(
\begin{array}{c}
y_3 \\
y_4 \\
y_5 \\
\end{array}
\right) = \left(
\begin{array}{c}
z_3 \\ 
z_4 \\
z_5 \\
\end{array}
\right)
\end{array}
\f]
where we have assumed that the two vectors \f${\bf y}\f$ and \f${\bf z}\f$
are re-ordered into ``block vectors'' in the same way as 
the vectors \f$\delta {\bf x}\f$ and \f${\bf r}\f$ in 
(@R[eqn:orig_linear_system]@) "the original linear system" are re-ordered into
the ``block vectors'' in
(@R[eqn:two_plus_three_reordered_linear_system]@).

In the code we have used matrixies full of 0s for each of the
replacement matricies, making it equivalent to the diagonal
preconditioner, as demonstrated below:
\f[
\begin{array}{c}
\left(
\begin{array}{cc}
J_{11} &  \\
& J_{22} \\
\end{array}
\right) \left(
\begin{array}{c}
y_1 \\
y_2 \\
\end{array}
\right) = \left(
\begin{array}{c}
z_1 \\ 
z_2 \\
\end{array}
\right) - \left(
\begin{array}{ccc}
& &  \\
 & &  \\
\end{array}
\right) \left(
\begin{array}{c}
z_3 \\
z_4 \\
z_5 \\
\end{array}
\right)
\\
\left(
\begin{array}{ccc}
J_{33} & &  \\
& J_{44} &  \\
 &  & J_{55} \\
\end{array}
\right) \left(
\begin{array}{c}
y_3 \\
y_4 \\
y_5 \\
\end{array}
\right) = \left(
\begin{array}{c}
z_3 \\ 
z_4 \\
z_5 \\
\end{array}
\right)
\end{array}
\f]

The implementation of the preconditioning operations in 
(@R[eqn:diag_prec]@)  can naturally be subdivided into two
distinct \c setup() and \c preconditioner\_solve(...) phases.
Assuming that the linear systems in (@R[eqn:two_plus_three_prec]@) are
solved exactly by a direct solver (an ``exact preconditioner'') that 
can pre-compute and store the LU decomposition of the diagonal matrix blocks,
the \c setup() phase involves the following operations
[text in square brackets refers to their \c oomph-lib specific 
implementation]:
- Set up any data structures/lookup tables that are required to 
extract matrix blocks from the original matrix
\f${\bf J}\f$ [by calling
the \c BlockPreconditioner::block\_setup(...) function]. 
- Extract the off diagonal blocks [using the 
\c BlockPreconditioner::get\_block(...)} function,
and replace them, in this case they are replaced by blocks full of 0s,
leading to an equivalence with the \c Simple preconditioner.
- Pass the new blocks, along with the blocking scheme to the
subsidiary preconditioners.

Once the \c setup() phase has been completed, the solution of the linear
system \f${\bf P} {\bf y} = {\bf z}\f$ by the \c preconditioner\_solve(...) 
function involves the following steps:
- Extract the two ``block vectors'' \f${\bf z}_i\f$ (for \f$i=1,2\f$)
from the vector \f${\bf z}\f$ [using the 
\c BlockPreconditioner::get\_block\_vector(...) function].
- Solve the linear systems \f${\bf J}_{ii} \ {\bf y}_i = 
{\bf z}_i\f$ for the vectors \f${\bf y}_i\f$ (for \f$i=1,2\f$).
- Combine the two ``block vectors'' \f${\bf y}_i\f$ (for \f$i=1,...,5\f$)
to the full-length vector \f${\bf y}\f$ [using the 
\c BlockPreconditioner::return\_block\_vector(...) function].

\subsubsection two_plus_three_upper_triangular_with_replace_setup The setup() function

The first thing that must be called at the beginning of every \c
setup(...) function is \c clean_up_my_memory(). This cleans up any
dynamically allocated memory.

\skip start_of_setup_for_two_plus_three_upper_triangular_with_replace
\until this->clean_up_my_memory();

Next we check that the number of degrees of freedom is 5, as the
preconditioner is desgined to only work for that number. The check is
only neccesary if \c OOMPH-LIB is complied with the \c PARANOID flag,
and as such is inside an \c #ifdef statement.

\skip //
\until #endif

Next, \c this->block_setup() is called, to set up any data structures
and/or lookup tables required to extract the desired blocks from the
Jacobian. For replacement it is necessary to have the mapping being the identity matrix.

\skip //
\until this->block_setup();

In order to replace blocks it is necessary to loop over those that are not wanted.

\skip //
\until {
\until {
\until {

The parts of the block that are still required are retrieved and stored and replacement parts constructed. These are then used to create a new matrix, stored in a \c DenseMatrix that's private data such that it may be cleaned up when no longer in use. This is because the replacement matrix needs to be stored by the preconditioner that does the replacement. It does not directly replace parts of the Jacobian, for you may not wish preconditioners master to the ones you are replacing in to be using the replaced blocks.

\skip //
\until replacement_column_index, replacement_row_start);

The replacement matrix is then passed to the \c set_replacement_dof_block matrix.

\skip //
\until }
\until }
\until }

The preconditioners and off diagonal products are then created and the preconditioners are setup.

\skip //
\until }

The off diagonal vector products require setting up in a more complex way than previously however as there is no predefined block to pass to it from the \c block_setup(...), instead we must make use of concatenation.

The first step in concatenation is to define the desired block. This is done by creating a \c VectorMatrix<BlockSelector>, \c BlockSelector is created purely for this, and is made use of via a \c select_block(...) function. To this is passed the matrix co-ordinates and generally a \c bool equal to \c true. 

\skip //
\until // End for loop over i (y)

We then request the block, using the \c get_concatenated_block(...) function, which takes our \c VectorMatrix<BlockSelector> as its sole argument.

\skip //
\until CR

The rest of the setup for the off diagonals is done as per usual.

\skip //
\until }

\subsubsection two_plus_three_upper_triangular_with_replace_solve The preconditioner_solve() function

The second subsidiary preconditioner is a block preconditioner and extracts the blocks itself from \c r and \c z, therefore it is just passed the argument directly.

\skip //
\until _solve(r,z);

Due to the concatenation used, we must extract \c r and \c z using \c
get_concatenated_block_vector(...), this takes the same mapping as we
used in the \c setup(...) function, the \c DoubleVector to extract
from and the \c Vector<DoubleVector> we wish to place the result into.

\skip //
\until  this->

\skip //
\until this->

With the vectors now setup the off diagonal matrix products and the first subsidiary preconditioner can be applied.

\skip //
\until }

\subsubsection two_plus_three_upper_triangular_with_replace_clean The clean_up_my_memory() function

The clean up memory functions purpose is to delete any existing
private data (and null it for safety purposes).

\skip //
\until // End of clean_up_my_memory function.

The reason that this is required is the preconditioner is called as
part of a linear solver program and may be used multiple times for
various nonlinear solves over the course of the program. An obvious
example of this is a time dependent problem. 

Therefore to stop the build-up of unnecessary memory \c
clean_up_my_memory() is called twice. Once at the beginning of 
\c setup() to avoid leakage if the preconditioner is reused, and the
second time is in the destructor (\c ~Simple()) to avoid memory leaks
if potential loops create and destroy the preconditioner, either
through \c new and \c delete or the preconditioner going out of scope.

\subsubsection two_plus_three_upper_triangular_with_replace_comments Comments

- In \ref two_plus_three_upper_triangular_with_replace_solve

 - Although we select all blocks with true, it is possible to select
   some or all with the flase flag. This would lead to the same result
   as it would be extracted and used but it would be a 0 matrix, and
   as such have no effect on the result as those blocks have been
   replaced with a matrix of 0s anyway. Although this is not useful
   here, it can be neccesary in other cases. eg if you have a square
   matrix and want to make it upper diagonal, if you do not select the
   bottom left with false, you are trying to make a matrix from 3
   square blocks, which cannot be done.


\subsection coarse_two_plus_two_plus_one Coarse two plus two plus one

\subsubsection coarse_two_plus_two_plus_one_theory Theory

In this example, we want to coarsen blocks, this allows us
to act upon it with a subsidiary block preconditioner, whilst the
subsidiary sees the coarsened blocks as a single block.

The original form selected by the preconditioner from the Jacobian is:
\f[
{\bf P} = 
\left(
\begin{array}{ccccc}
J_{11} & J_{12} & J_{13} & J_{14} & J_{15} \\
J_{21} & J_{22} & J_{23} & J_{24} & J_{25} \\
 & & J_{33} & J_{34} & J_{35} \\
 & & J_{43} & J_{44} & J_{45} \\
 & & J_{53} & J_{54} & J_{55} \\
\end{array}
\right).
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:\:
@E[eqn:coarse_two_plus_two_plus_one_reordered_linear_system]@
\f]

This is then treated by upper triangular subsidiary systems, both of
which see the blocks as 2x2, as the bottom right 3x3 block is
coarsened into a 2x2 system.

Both take the 2x2 system, do an upper triangular solve on each of the
diagonal blocks, which for the purposes of the blocks is equivalent to
an LU decomposition, with modification of the right hand side as
apropriate for the off diagonal block. 
\f[
{\bf P} = 
\left(
\begin{array}{cc}
J_{11} & J_{12} \\
 & J_{22} \\
\end{array}
\right).
\f]

The end result is almost equivalent to the upper triangular system
with the J_{34} being able to be trivially repalced if the solution is
wished to be compared:

\f[
{\bf P} = 
\left(
\begin{array}{ccccc}
J_{11} & J_{12} & J_{13} & J_{14} & J_{15} \\
J_{21} & J_{22} & J_{23} & J_{24} & J_{25} \\
 & & J_{33} & J_{34} & J_{35} \\
 & & J_{34} & J_{44} & J_{45} \\
 & & & & J_{55} \\
\end{array}
\right).
\f]



\subsubsection coarse_two_plus_two_plus_one_setup The setup() function

The first thing that must be called at the beginning of every \c
setup(...) function is \c clean_up_my_memory(). This cleans up any
dynamically allocated memory.

\skip start_of_setup_for_coarse_two_plus_two_plus_one
\until this->clean_up_my_memory();

Next we check that the number of degrees of freedom is 5, as the
preconditioner is designed to only work for that number. The check is
only necessary if \c OOMPH-LIB is complied with the \c PARANOID flag,
and as such is inside an \c #ifdef statement.

\skip //
\until #endif

Next, \c this->block_setup() is called, to set up any data structures
and/or lookup tables required to extract the desired blocks from the
Jacobian.

\skip //
\until this->block_setup();

In order to replace blocks it is necessary to loop over those that are not wanted.

\skip //
\until {
\until {

The parts of the block that are still required are retrieved and stored and replacement parts constructed. These are then used to create a new matrix, stored in a \c DenseMatrix that's private data such that it may be cleaned up when no longer in use. This is because the replacement matrix needs to be stored by the preconditioner that does the replacement. It does not directly replace parts of the Jacobian, for you may not wish preconditioners master to the ones you are replacing in to be using the replaced blocks.

\skip //
\until replacement_column_index, replacement_row_start);

The replacement matrix is then passed to the \c set_replacement_dof_block matrix.

\skip //
\until }// End of i loop.

The first preconditioner is created and setup. Then the second one is created.

\skip //
\until  Second_subsidiary_preconditioner_pt=block_prec_pt;

We desire the second preconditioner to act on a coarsened system, as such we first need to setup the mapping to the new corase system.

The first thing that requires is a \c Vector<Vector<unsigned>>. The first \c Vector indicates the "coarse" blocks that will be created in the subsidiary preconditioner.

The second \c Vector indicates the dofs in the master preconditioner that go into the "coarse" blocks specified by the first \c Vector; ie the blocks in the subsidiary preconditioner.

\skip unsigned n_sub_dof_types=2;
\until doftype_coarsen_map_coarse[1][0]

However the \c unsigned values stored do not directly refer to the
doftypes in the master preconditioner, instead they go via a secondary
\c Vector. The values in the \c doftype_coarsen_map_coarse refer to
the index of \c doftype_in_master_coarse. This means that if \c doftype_in_master_coarse[0] is 1 then if
\c doftype_coarsen_map_coarse[i][j]=0 the ith "coarse" block in the
subsidiary preconditioner contains at least j of the master's blocks,
and the jth block in the ith "coarse" block is the dof of the master
preconditioner stored in \c doftype_in_master_coarse[0], which in this example is 1.

\skip Vector<unsigned> doftype_in_master_coarse
\until doftype_in_master_coarse[2]

The subsidiary preconditioner is then turned into a subsidiary by passing the master preconditioner and the two \c Vector.

\skip block_prec_pt->
\until  doftype_coarsen_map_coarse);

The preconditioner and concatenated off digonals are then setup as per normal.

\skip //
\until }// End of setup

\subsubsection coarse_two_plus_two_plus_one_solve The preconditioner_solve() function

Firstly the second preconditioner's result is ascertained, so that it
can be back substituted later.

\skip //
\until _subsidiary_preconditioner_pt

Then the \c Vector \c r and \c Vector \c z are retrieved using an identical
coarsening scheme to that used in \c setup().

\skip //
\until this->get_concatenated_block_vector(block1_vec_number,z,z_1);

The rest of the solve is done as per normal for a 2 plus 3 system with
an off diagonal, using subsidiary preconditioners.

\skip //
\until }

\subsubsection coarse_two_plus_two_plus_one_clean The clean_up_my_memory() function

The clean up memory functions purpose is to delete any existing
private data (and null it for safety purposes).

\skip //
\until // End of clean_up_my_memory function.

The reason that this is required is the preconditioner is called as
part of a linear solver program and may be used multiple times for
various nonlinear solves over the course of the program. An obvious
example of this is a time dependent problem. 

Therefore to stop the build-up of unnecessary memory \c
clean_up_my_memory() is called twice. Once at the beginning of 
\c setup() to avoid leakage if the preconditioner is reused, and the
second time is in the destructor (\c ~Simple()) to avoid memory leaks
if potential loops create and destroy the preconditioner, either
through \c new and \c delete or the preconditioner going out of scope.

